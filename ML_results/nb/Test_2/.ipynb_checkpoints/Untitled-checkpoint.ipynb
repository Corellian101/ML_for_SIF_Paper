{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4eaffa",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0c7de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from joblib import dump, load\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b9365",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef8801",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def poly_svm(train_data):\n",
    "    degrees = [1,2,3,4]\n",
    "    times = []\n",
    "    regs = []\n",
    "    for degree in degrees:\n",
    "        t0 = time.time()\n",
    "        reg = SVR(kernel=\"poly\", degree = degree)\n",
    "        reg.fit(train_data[:,:-1], train_data[:,-1])\n",
    "        t1 = time.time()\n",
    "        times.append(t1-t0)\n",
    "        regs.append(reg)\n",
    "        print(\"Done degree {}\".format(degree))\n",
    "    return times, regs\n",
    "\n",
    "def poly_svm_boost(train_data, M_train_data, data_type):\n",
    "    degrees = [1,2,3,4]\n",
    "    times = []\n",
    "    M_regs = []\n",
    "    g_regs = []\n",
    "    for degree in degrees:\n",
    "        t0 = time.time()\n",
    "        reg = SVR(kernel=\"poly\", degree = degree)\n",
    "        reg.fit(M_train_data[:,:-1], M_train_data[:,-1])\n",
    "        M = reg.predict(train_data[:,:2])\n",
    "        train_data[:,-1] = train_data[:,-1]/M\n",
    "        reg_g = SVR(kernel=\"poly\", degree = degree)\n",
    "        if data_type == 'le':\n",
    "            reg_g.fit(train_data[:,1:-1], train_data[:,-1])\n",
    "        elif data_type == 'g':\n",
    "            reg_g.fit(train_data[:,:-1], train_data[:,-1])\n",
    "        else:\n",
    "            raise Exception(\"Invalid data type\")\n",
    "        t1 = time.time()\n",
    "        times.append(t1-t0)\n",
    "        M_regs.append(reg)\n",
    "        g_regs.append(reg_g)\n",
    "        print(\"Done degree {}\".format(degree))\n",
    "    \n",
    "    return times, M_regs, g_regs\n",
    "\n",
    "def rbf_svm(train_data):\n",
    "    t0 = time.time()\n",
    "    reg = SVR(kernel=\"rbf\")\n",
    "    reg.fit(train_data[:,:-1], train_data[:,-1])\n",
    "    t1 = time.time()\n",
    "    return t1-t0, reg\n",
    "\n",
    "def rbf_svm_boost(train_data, M_train_data, data_type):\n",
    "    t0 = time.time()\n",
    "    reg = SVR(kernel=\"rbf\")\n",
    "    reg.fit(M_train_data[:,:-1], M_train_data[:,-1])\n",
    "    M = reg.predict(train_data[:,:2])\n",
    "    train_data[:,-1] = train_data[:,-1]/M\n",
    "    reg_g = SVR(kernel=\"rbf\")\n",
    "    if data_type == 'le':\n",
    "        reg_g.fit(train_data[:,1:-1], train_data[:,-1])\n",
    "    elif data_type == 'g':\n",
    "        reg_g.fit(train_data[:,:-1], train_data[:,-1])\n",
    "    else:\n",
    "        raise Exception(\"Invalid data type\")\n",
    "    t1 = time.time()\n",
    "    return t1-t0, reg, reg_g\n",
    "\n",
    "def NN(data):\n",
    "    X_train = data[:,:-1]\n",
    "    y_train = data[:,-1]\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "\n",
    "    #get number of columns in training data\n",
    "    n_cols = X_train.shape[1]\n",
    "\n",
    "    #add model layers\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    early_stopping_monitor = EarlyStopping(patience=10)\n",
    "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, callbacks=[early_stopping_monitor])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56bfe62",
   "metadata": {},
   "source": [
    "# RN Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd4ca4",
   "metadata": {},
   "source": [
    "## $a/c \\le 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_le1 = np.load(\"data/1_RN_data_ac_le1.npy\")\n",
    "d1_le1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059acb9f",
   "metadata": {},
   "source": [
    "### No Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3535e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_boosting(data, data_name):\n",
    "    ###################################\n",
    "    ########## No boosting ############\n",
    "    ###################################\n",
    "    # Poly SVM\n",
    "    times, regs = poly_svm(data)\n",
    "    # saving models\n",
    "    i = 1\n",
    "    for reg in regs:\n",
    "        dump(reg, 'results/no_boosting/run_2/models/poly/{}_poly_degree_{}.joblib'.format(data_name,\n",
    "                                                                                     i))\n",
    "        i += 1\n",
    "    np.save(\"results/no_boosting/run_2/times/{}_poly_times.npy\".format(data_name), times)\n",
    "\n",
    "    # RBF SVM\n",
    "    rbf_time, rbf_reg = rbf_svm(data)\n",
    "    # saving models\n",
    "    dump(rbf_reg, 'results/no_boosting/run_2/models/rbf/{}_rbf.joblib'.format(data_name))\n",
    "    np.save(\"results/no_boosting/run_2/times/{}_rbf_times.npy\".format(data_name), rbf_time)\n",
    "    \n",
    "#     # NN \n",
    "#     model = NN(data)\n",
    "#     model.save('results/no_boosting/run_2/models/NN/{}.h5'.format(data_name))\n",
    "    return times, regs, rbf_time, rbf_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24226bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "times, regs, rbf_time, rbf_reg = no_boosting(d1_le1, \"d1_le1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c3749",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc60386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosting(full_data, M_data, data_name, data_type):\n",
    "    ###################################\n",
    "    ############ Boosting #############\n",
    "    ###################################\n",
    "    # Poly SVM\n",
    "    times, M_regs, g_regs = poly_svm_boost(full_data, M_data, data_type)\n",
    "    \n",
    "    # saving models\n",
    "    for i in range(4):\n",
    "        dump(M_regs[i], 'results/boosting/models/poly/M_{}_poly_degree_{}.joblib'.format(data_name,i))\n",
    "        dump(g_regs[i], 'results/boosting/models/poly/g_{}_poly_degree_{}.joblib'.format(data_name,i))\n",
    "\n",
    "    np.save(\"results/boosting/times/{}_poly_times.npy\".format(data_name), times)\n",
    "\n",
    "    # RBF SVM\n",
    "    rbf_times, rbf_M_reg, rbf_g_reg = rbf_svm_boost(full_data, M_data, data_type)\n",
    "    \n",
    "    # saving models\n",
    "    dump(rbf_M_reg, 'results/boosting/models/rbf/M_{}_rbf.joblib'.format(data_name))\n",
    "    dump(rbf_g_reg, 'results/boosting/models/rbf/g_{}_rbf.joblib'.format(data_name))\n",
    "\n",
    "    np.save(\"results/boosting/times/{}_rbf_times.npy\".format(data_name), rbf_times)\n",
    "    \n",
    "#     # NN \n",
    "#     model = NN(data)\n",
    "#     model.save('results/no_boosting/run_2/models/NN/{}.h5'.format(data_name))\n",
    "    return times, M_regs, g_regs, rbf_times, rbf_M_reg, rbf_g_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in d1_le1:\n",
    "    if (row[2] > 1.5 and row[2] < 1.65):\n",
    "        data.append(np.delete(row, 2))\n",
    "M_data = np.array(data)\n",
    "\n",
    "boost_times, M_regs, g_regs, rbf_boost_times, rbf_M_regs, rbf_g_regs = boosting(d1_le1,\n",
    "                                                                                M_data, \n",
    "                                                                                \"d1_le1\", \n",
    "                                                                                \"le\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c641a",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f7ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test dataset\n",
    "df = pd.read_csv(\"../../data/3_datasets_new/test/1_RN_data_TEST.csv\")\n",
    "df.drop([\"c/b\", \"F\"], axis=1, inplace=True)\n",
    "d1_test = df.to_numpy()\n",
    "d1_test_le = d1_test[d1_test[:,0]<=1]\n",
    "d1_test_g = d1_test[d1_test[:,0]>1]\n",
    "d1_test.shape, d1_test_g.shape, d1_test_le.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a02f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reg, X, Y):\n",
    "    results = reg.predict(X)\n",
    "    mse = np.sum((results - Y)**2)/len(data)\n",
    "    return mse, results\n",
    "\n",
    "algos = [\"Poly 1\", \"Poly 2\", \"Poly 3\", \"Poly 4\", \"rbf\"]\n",
    "no_boost_mse = []\n",
    "boost_mse = []\n",
    "\n",
    "# Poly\n",
    "for i in range(4):\n",
    "    # NO BOOST\n",
    "    mse, _ = evaluate(regs[i], d1_test_le[:,:-1], d1_test_le[:,-1])\n",
    "    no_boost_mse.append(mse)\n",
    "    \n",
    "    # BOOST\n",
    "    _, M = evaluate(M_regs[i], d1_test_le[:,:2], d1_test_le[:,-1])\n",
    "    _, g = evaluate(g_regs[i], d1_test_le[:,1:-1], d1_test_le[:,-1])\n",
    "    boost_mse.append(np.sum((M*g - d1_test_le[:,-1])**2)/len(d1_test_le[:,-1]))\n",
    "    \n",
    "# RBF\n",
    "# NO BOOST\n",
    "mse, _ = evaluate(rbf_reg, d1_test_le[:,:-1], d1_test_le[:,-1])\n",
    "no_boost_mse.append(mse)\n",
    "\n",
    "# BOOST\n",
    "_, M = evaluate(rbf_M_regs, d1_test_le[:,:2], d1_test_le[:,-1])\n",
    "_, g = evaluate(rbf_g_regs, d1_test_le[:,1:-1], d1_test_le[:,-1])\n",
    "boost_mse.append(np.sum((M*g - d1_test_le[:,-1])**2)/len(d1_test_le[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed4c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(algos, no_boost_mse, label=\"No Boosting\")\n",
    "plt.plot(algos, boost_mse, label=\"Boosting\")\n",
    "plt.legend()\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd049f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# $a/c >1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b14bcc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d1_le1 = np.load(\"data/1_RN_data_ac_g1.npy\")\n",
    "d1_le1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32837a96",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# No Boosting\n",
    "times, regs, rbf_time, rbf_reg = no_boosting(d1_le1, \"d1_g1\")\n",
    "\n",
    "# Boosting\n",
    "data = []\n",
    "for row in d1_le1:\n",
    "    if (row[2] > 1.5 and row[2] < 1.65):\n",
    "        data.append(np.delete(row, 2))\n",
    "M_data = np.array(data)\n",
    "\n",
    "boost_times, M_regs, g_regs, rbf_boost_times, rbf_M_regs, rbf_g_regs = boosting(d1_le1,\n",
    "                                                                                M_data, \n",
    "                                                                                \"d1_g1\", \n",
    "                                                                                \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36b044",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Loading test dataset\n",
    "df = pd.read_csv(\"../../data/3_datasets_new/test/1_RN_data_TEST.csv\")\n",
    "df.drop([\"c/b\", \"F\"], axis=1, inplace=True)\n",
    "d1_test = df.to_numpy()\n",
    "d1_test_le = d1_test[d1_test[:,0]<=1]\n",
    "d1_test_g = d1_test[d1_test[:,0]>1]\n",
    "d1_test.shape, d1_test_g.shape, d1_test_le.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6f790",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "algos = [\"Poly 1\", \"Poly 2\", \"Poly 3\", \"Poly 4\", \"rbf\"]\n",
    "no_boost_mse_1 = []\n",
    "boost_mse_1 = []\n",
    "\n",
    "# Poly\n",
    "for i in range(4):\n",
    "    # NO BOOST\n",
    "    mse, _ = evaluate(regs[i], d1_test_le[:,:-1], d1_test_le[:,-1])\n",
    "    no_boost_mse_1.append(mse)\n",
    "    \n",
    "    # BOOST\n",
    "    _, M = evaluate(M_regs[i], d1_test_le[:,:2], d1_test_le[:,-1])\n",
    "    _, g = evaluate(g_regs[i], d1_test_le[:,:-1], d1_test_le[:,-1])\n",
    "    boost_mse_1.append(np.sum((M*g - d1_test_le[:,-1])**2)/len(d1_test_le[:,-1]))\n",
    "    \n",
    "# RBF\n",
    "# NO BOOST\n",
    "mse, _ = evaluate(rbf_reg, d1_test_le[:,:-1], d1_test_le[:,-1])\n",
    "no_boost_mse_1.append(mse)\n",
    "\n",
    "# BOOST\n",
    "_, M = evaluate(rbf_M_regs, d1_test_le[:,:2], d1_test_le[:,-1])\n",
    "_, g = evaluate(rbf_g_regs, d1_test_le[:,:-1], d1_test_le[:,-1])\n",
    "boost_mse_1.append(np.sum((M*g - d1_test_le[:,-1])**2)/len(d1_test_le[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d6c76",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(algos, no_boost_mse, label=\"No Boosting (a/c<=1)\")\n",
    "plt.plot(algos, boost_mse, label=\"Boosting (a/c<=1)\")\n",
    "plt.plot(algos, no_boost_mse_1, label=\"No Boosting (a/c>1)\")\n",
    "plt.plot(algos, boost_mse_1, label=\"Boosting (a/c>1)\")\n",
    "plt.legend()\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8569cf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## $0< a/c <2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411711fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Loading test dataset\n",
    "df = pd.read_csv(\"../../data/3_datasets_new/test/1_RN_data_TEST.csv\")\n",
    "df.drop([\"c/b\", \"F\"], axis=1, inplace=True)\n",
    "d_test = df.to_numpy()\n",
    "\n",
    "# Testing\n",
    "MSE = []\n",
    "for i in range(1, 5):\n",
    "    reg = load('../Test_1/poly_svm/models/d1/d1_poly_degree_{}.joblib'.format(i))\n",
    "    results = reg.predict(d_test[:,:-1])\n",
    "    mse = np.sum((results - d_test[:,-1])**2)/len(d_test)\n",
    "    print(\"Mean squared error: \", mse)\n",
    "    MSE.append(mse)\n",
    "    \n",
    "reg = load('../Test_1/rbf_svm/d1_rbf.joblib')\n",
    "results = reg.predict(d_test[:,:-1])\n",
    "mse = np.sum((results - d_test[:,-1])**2)/len(d_test)\n",
    "print(\"Mean squared error: \", mse)\n",
    "MSE.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aeb42d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(algos, no_boost_mse, label=\"No Boosting (a/c<=1)\")\n",
    "plt.plot(algos, boost_mse, label=\"Boosting (a/c<=1)\")\n",
    "plt.plot(algos, no_boost_mse_1, label=\"No Boosting (a/c>1)\")\n",
    "plt.plot(algos, boost_mse_1, label=\"Boosting (a/c>1)\")\n",
    "plt.plot(algos, MSE, label=\"All points\")\n",
    "plt.legend()\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60acc3",
   "metadata": {},
   "source": [
    "# RN Eqn dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7411210",
   "metadata": {},
   "source": [
    "### a/c <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_le1 = np.load(\"data/2_RN_eqn_ac_le1.npy\")\n",
    "\n",
    "# No Boosting\n",
    "times, regs, rbf_time, rbf_reg = no_boosting(d1_le1, \"d2_le1\")\n",
    "\n",
    "# Boosting\n",
    "data = []\n",
    "for row in d1_le1:\n",
    "    if (row[2] > 1.5 and row[2] < 1.65):\n",
    "        data.append(np.delete(row, 2))\n",
    "M_data = np.array(data)\n",
    "\n",
    "boost_times, M_regs, g_regs, rbf_boost_times, rbf_M_regs, rbf_g_regs = boosting(d1_le1,\n",
    "                                                                                M_data, \n",
    "                                                                                \"d2_le1\", \n",
    "                                                                                \"le\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbcbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test dataset\n",
    "df = pd.read_csv(\"../../data/3_datasets_new/test/\")\n",
    "df.drop([\"c/b\", \"F\"], axis=1, inplace=True)\n",
    "d1_test = df.to_numpy()\n",
    "d1_test_le = d1_test[d1_test[:,0]<=1]\n",
    "d1_test_g = d1_test[d1_test[:,0]>1]\n",
    "d1_test.shape, d1_test_g.shape, d1_test_le.shape\n",
    "\n",
    "algos = [\"Poly 1\", \"Poly 2\", \"Poly 3\", \"Poly 4\", \"rbf\"]\n",
    "no_boost_mse = []\n",
    "boost_mse = []\n",
    "\n",
    "# Poly\n",
    "for i in range(4):\n",
    "    # NO BOOST\n",
    "    mse, _ = evaluate(regs[i], d1_test_le[:,:-1], d1_test_le[:,-1])\n",
    "    no_boost_mse.append(mse)\n",
    "    \n",
    "    # BOOST\n",
    "    _, M = evaluate(M_regs[i], d1_test_le[:,:2], d1_test_le[:,-1])\n",
    "    _, g = evaluate(g_regs[i], d1_test_le[:,1:-1], d1_test_le[:,-1])\n",
    "    boost_mse.append(np.sum((M*g - d1_test_le[:,-1])**2)/len(d1_test_le[:,-1]))\n",
    "    \n",
    "# RBF\n",
    "# NO BOOST\n",
    "mse, _ = evaluate(rbf_reg, d1_test_le[:,:-1], d1_test_le[:,-1])\n",
    "no_boost_mse.append(mse)\n",
    "\n",
    "# BOOST\n",
    "_, M = evaluate(rbf_M_regs, d1_test_le[:,:2], d1_test_le[:,-1])\n",
    "_, g = evaluate(rbf_g_regs, d1_test_le[:,1:-1], d1_test_le[:,-1])\n",
    "boost_mse.append(np.sum((M*g - d1_test_le[:,-1])**2)/len(d1_test_le[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffbe773",
   "metadata": {},
   "source": [
    "### a/c > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21deae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ace26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a28f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from joblib import dump, load\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def poly_svm(train_data):\n",
    "    degrees = [1,2,3,4]\n",
    "    times = []\n",
    "    regs = []\n",
    "    for degree in degrees:\n",
    "        t0 = time.time()\n",
    "        reg = SVR(kernel=\"poly\", degree = degree)\n",
    "        reg.fit(train_data[:,:-1], train_data[:,-1])\n",
    "        t1 = time.time()\n",
    "        times.append(t1-t0)\n",
    "        regs.append(reg)\n",
    "        print(\"Done degree {}\".format(degree))\n",
    "    return times, regs\n",
    "\n",
    "def poly_svm_boost(train_data, M_train_data, data_type):\n",
    "    degrees = [1,2,3,4]\n",
    "    times = []\n",
    "    M_regs = []\n",
    "    g_regs = []\n",
    "    for degree in degrees:\n",
    "        t0 = time.time()\n",
    "        reg = SVR(kernel=\"poly\", degree = degree)\n",
    "        reg.fit(M_train_data[:,:-1], M_train_data[:,-1])\n",
    "        M = reg.predict(train_data[:,:2])\n",
    "        train_data[:,-1] = train_data[:,-1]/M\n",
    "        reg_g = SVR(kernel=\"poly\", degree = degree)\n",
    "        if data_type == 'le':\n",
    "            reg_g.fit(train_data[:,1:-1], train_data[:,-1])\n",
    "        elif data_type == 'g':\n",
    "            reg_g.fit(train_data[:,:-1], train_data[:,-1])\n",
    "        else:\n",
    "            raise Exception(\"Invalid data type\")\n",
    "        t1 = time.time()\n",
    "        times.append(t1-t0)\n",
    "        M_regs.append(reg)\n",
    "        g_regs.append(reg_g)\n",
    "        print(\"Done degree {}\".format(degree))\n",
    "\n",
    "    return times, M_regs, g_regs\n",
    "\n",
    "def rbf_svm(train_data):\n",
    "    t0 = time.time()\n",
    "    reg = SVR(kernel=\"rbf\")\n",
    "    reg.fit(train_data[:,:-1], train_data[:,-1])\n",
    "    t1 = time.time()\n",
    "    return t1-t0, reg\n",
    "\n",
    "def rbf_svm_boost(train_data, M_train_data, data_type):\n",
    "    t0 = time.time()\n",
    "    reg = SVR(kernel=\"rbf\")\n",
    "    reg.fit(M_train_data[:,:-1], M_train_data[:,-1])\n",
    "    M = reg.predict(train_data[:,:2])\n",
    "    train_data[:,-1] = train_data[:,-1]/M\n",
    "    reg_g = SVR(kernel=\"rbf\")\n",
    "    if data_type == 'le':\n",
    "        reg_g.fit(train_data[:,1:-1], train_data[:,-1])\n",
    "    elif data_type == 'g':\n",
    "        reg_g.fit(train_data[:,:-1], train_data[:,-1])\n",
    "    else:\n",
    "        raise Exception(\"Invalid data type\")\n",
    "    t1 = time.time()\n",
    "    return t1-t0, reg, reg_g\n",
    "\n",
    "def no_boosting(data, data_name):\n",
    "    ###################################\n",
    "    ########## No boosting ############\n",
    "    ###################################\n",
    "    # Poly SVM\n",
    "    times, regs = poly_svm(data)\n",
    "    # saving models\n",
    "    i = 1\n",
    "    for reg in regs:\n",
    "        dump(reg, 'results/no_boosting/run_2/models/poly/{}_poly_degree_{}.joblib'.format(data_name,\n",
    "                                                                                     i))\n",
    "        i += 1\n",
    "    np.save(\"results/no_boosting/run_2/times/{}_poly_times.npy\".format(data_name), times)\n",
    "\n",
    "    # RBF SVM\n",
    "    rbf_time, rbf_reg = rbf_svm(data)\n",
    "    # saving models\n",
    "    dump(rbf_reg, 'results/no_boosting/run_2/models/rbf/{}_rbf.joblib'.format(data_name))\n",
    "    np.save(\"results/no_boosting/run_2/times/{}_rbf_times.npy\".format(data_name), rbf_time)\n",
    "    return times, regs, rbf_time, rbf_reg\n",
    "\n",
    "def boosting(full_data, M_data, data_name, data_type):\n",
    "    ###################################\n",
    "    ############ Boosting #############\n",
    "    ###################################\n",
    "    # Poly SVM\n",
    "    times, M_regs, g_regs = poly_svm_boost(full_data, M_data, data_type)\n",
    "\n",
    "    # saving models\n",
    "    for i in range(4):\n",
    "        dump(M_regs[i], 'results/boosting/models/poly/M_{}_poly_degree_{}.joblib'.format(data_name,i))\n",
    "        dump(g_regs[i], 'results/boosting/models/poly/g_{}_poly_degree_{}.joblib'.format(data_name,i))\n",
    "\n",
    "    np.save(\"results/boosting/times/{}_poly_times.npy\".format(data_name), times)\n",
    "\n",
    "    # RBF SVM\n",
    "    rbf_times, rbf_M_reg, rbf_g_reg = rbf_svm_boost(full_data, M_data, data_type)\n",
    "\n",
    "    # saving models\n",
    "    dump(rbf_M_reg, 'results/boosting/models/rbf/M_{}_rbf.joblib'.format(data_name))\n",
    "    dump(rbf_g_reg, 'results/boosting/models/rbf/g_{}_rbf.joblib'.format(data_name))\n",
    "\n",
    "    np.save(\"results/boosting/times/{}_rbf_times.npy\".format(data_name), rbf_times)\n",
    "    return times, M_regs, g_regs, rbf_times, rbf_M_reg, rbf_g_reg\n",
    "\n",
    "def evaluate(reg, X, Y):\n",
    "    results = reg.predict(X)\n",
    "    mse = np.sum((results - Y)**2)/len(X)\n",
    "    return mse, results\n",
    "\n",
    "def testing(d_le1, d_g1, d_test, data_name):\n",
    "    ################# a/c <= 1###########################\n",
    "    # No Boosting\n",
    "    times, regs, rbf_time, rbf_reg = no_boosting(d_le1, data_name+\"_le1\")\n",
    "    # Boosting\n",
    "    data = []\n",
    "    for row in d_le1:\n",
    "        if (row[2] > 1.5 and row[2] < 1.65):\n",
    "            data.append(np.delete(row, 2))\n",
    "    M_data = np.array(data)\n",
    "    boost_times, M_regs, g_regs, rbf_boost_times, rbf_M_regs, rbf_g_regs = boosting(d_le1,M_data,data_name+\"_le1\",\"le\")\n",
    "    # Testing\n",
    "    d_test_le = d_test[d_test[:,0]<=1]\n",
    "    no_boost_mse = []\n",
    "    boost_mse = []\n",
    "    # Poly\n",
    "    for i in range(4):\n",
    "        # NO BOOST\n",
    "        mse, _ = evaluate(regs[i], d_test_le[:,:-1], d_test_le[:,-1])\n",
    "        no_boost_mse.append(mse)\n",
    "\n",
    "        # BOOST\n",
    "        _, M = evaluate(M_regs[i], d_test_le[:,:2], d_test_le[:,-1])\n",
    "        _, g = evaluate(g_regs[i], d_test_le[:,1:-1], d_test_le[:,-1])\n",
    "        boost_mse.append(np.sum((M*g - d_test_le[:,-1])**2)/len(d_test_le[:,-1]))\n",
    "\n",
    "    # RBF\n",
    "    # NO BOOST\n",
    "    mse, _ = evaluate(rbf_reg, d_test_le[:,:-1], d_test_le[:,-1])\n",
    "    no_boost_mse.append(mse)\n",
    "\n",
    "    # BOOST\n",
    "    _, M = evaluate(rbf_M_regs, d_test_le[:,:2], d_test_le[:,-1])\n",
    "    _, g = evaluate(rbf_g_regs, d_test_le[:,1:-1], d_test_le[:,-1])\n",
    "    boost_mse.append(np.sum((M*g - d_test_le[:,-1])**2)/len(d_test_le[:,-1]))\n",
    "\n",
    "    ################# a/c > 1###########################\n",
    "    # No Boosting\n",
    "    times, regs, rbf_time, rbf_reg = no_boosting(d_g1, data_name+\"_g1\")\n",
    "    # Boosting\n",
    "    data = []\n",
    "    for row in d_g1:\n",
    "        if (row[2] > 1.5 and row[2] < 1.65):\n",
    "            data.append(np.delete(row, 2))\n",
    "    M_data = np.array(data)\n",
    "    boost_times, M_regs, g_regs, rbf_boost_times, rbf_M_regs, rbf_g_regs = boosting(d_g1,M_data,data_name+\"_g1\",\"g\")\n",
    "    # Testing\n",
    "    d_test_g = d_test[d_test[:,0]>1]\n",
    "    no_boost_mse_g = []\n",
    "    boost_mse_g = []\n",
    "    # Poly\n",
    "    for i in range(4):\n",
    "        # NO BOOST\n",
    "        mse, _ = evaluate(regs[i], d_test_g[:,:-1], d_test_g[:,-1])\n",
    "        no_boost_mse_g.append(mse)\n",
    "\n",
    "        # BOOST\n",
    "        _, M = evaluate(M_regs[i], d_test_g[:,:2], d_test_g[:,-1])\n",
    "        _, g = evaluate(g_regs[i], d_test_g[:,1:-1], d_test_g[:,-1])\n",
    "        boost_mse_g.append(np.sum((M*g - d_test_g[:,-1])**2)/len(d_test_g[:,-1]))\n",
    "\n",
    "    # RBF\n",
    "    # NO BOOST\n",
    "    mse, _ = evaluate(rbf_reg, d_test_g[:,:-1], d_test_g[:,-1])\n",
    "    no_boost_mse_g.append(mse)\n",
    "\n",
    "    # BOOST\n",
    "    _, M = evaluate(rbf_M_regs, d_test_g[:,:2], d_test_g[:,-1])\n",
    "    _, g = evaluate(rbf_g_regs, d_test_g[:,1:-1], d_test_g[:,-1])\n",
    "    boost_mse_g.append(np.sum((M*g - d_test_g[:,-1])**2)/len(d_test_g[:,-1]))\n",
    "\n",
    "    return boost_mse, no_boost_mse, boost_mse_g, no_boost_mse_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e05790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done degree 1\n",
      "Done degree 2\n",
      "Done degree 3\n",
      "Done degree 4\n",
      "Done degree 1\n",
      "Done degree 2\n",
      "Done degree 3\n",
      "Done degree 4\n",
      "Done degree 1\n",
      "Done degree 2\n",
      "Done degree 3\n",
      "Done degree 4\n",
      "Done degree 1\n",
      "Done degree 2\n",
      "Done degree 3\n",
      "Done degree 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but SVR is expecting 3 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc/b\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m d1_test \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m----> 7\u001b[0m boost_mse, no_boost_mse, boost_mse_g, no_boost_mse_g \u001b[38;5;241m=\u001b[39m \u001b[43mtesting\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_le1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md1_le1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_g1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md1_g1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43md_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md1_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mtesting\u001b[0;34m(d_le1, d_g1, d_test, data_name)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# BOOST\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     _, M \u001b[38;5;241m=\u001b[39m evaluate(M_regs[i], d_test_g[:,:\u001b[38;5;241m2\u001b[39m], d_test_g[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 187\u001b[0m     _, g \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_regs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_test_g\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_test_g\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     boost_mse_g\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39msum((M\u001b[38;5;241m*\u001b[39mg \u001b[38;5;241m-\u001b[39m d_test_g[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(d_test_g[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# RBF\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# NO BOOST\u001b[39;00m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(reg, X, Y)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(reg, X, Y):\n\u001b[0;32m--> 125\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((results \u001b[38;5;241m-\u001b[39m Y)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(X)\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mse, results\n",
      "File \u001b[0;32m~/dev/ML_for_SIF_Paper/sif/lib/python3.9/site-packages/sklearn/svm/_base.py:414\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/dev/ML_for_SIF_Paper/sif/lib/python3.9/site-packages/sklearn/svm/_base.py:592\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    589\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 592\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39misspmatrix(X):\n\u001b[1;32m    602\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/dev/ML_for_SIF_Paper/sif/lib/python3.9/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/dev/ML_for_SIF_Paper/sif/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 2 features, but SVR is expecting 3 features as input."
     ]
    }
   ],
   "source": [
    "d1_le1 = np.load(\"data/1_RN_data_ac_le1.npy\")\n",
    "d1_g1 = np.load(\"data/1_RN_data_ac_g1.npy\")\n",
    "df = pd.read_csv(\"../../data/3_datasets_new/test/1_RN_data_TEST.csv\")\n",
    "df.drop([\"c/b\", \"F\"], axis=1, inplace=True)\n",
    "d1_test = df.to_numpy()\n",
    "\n",
    "boost_mse, no_boost_mse, boost_mse_g, no_boost_mse_g = testing(d_le1=d1_le1, d_g1=d1_g1, \n",
    "                                                               d_test=d1_test, data_name=\"d1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f34ff4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
